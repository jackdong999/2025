{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51d8c05",
   "metadata": {},
   "source": [
    "# ü§ñ Building AI Agents With Function Calling\n",
    "\n",
    "In this notebook, you‚Äôll learn how to turn a language model into an **agent**, a system that can not only talk, but also *act*.  \n",
    "We do this by giving the model **tools**: small functions it can call to do real work like math, weather lookup, currency conversion, and more.\n",
    "\n",
    "Function calling is how modern LLMs connect to the outside world. Instead of guessing answers, the model can decide: ‚ÄúAh, this needs a tool,‚Äù and then request exactly the function and arguments it needs.\n",
    "\n",
    "Your job in this notebook isn‚Äôt to write the tools themselves, those are provided. Your job is to:\n",
    "\n",
    "- Define tool schemas  \n",
    "- Inform the model which tools exist  \n",
    "- Let the model choose when to use them  \n",
    "- Run the tool it requests  \n",
    "- Return the result so it can finish the response  \n",
    "\n",
    "By the end, you‚Äôll know how real AI agents are built and how to make LLMs interact with reliable code, APIs, and external systems.\n",
    "\n",
    "Let‚Äôs get started. üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20b9532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import requests\n",
    "import json\n",
    "from functools import lru_cache\n",
    "from sympy import symbols, sympify, simplify, solve, diff, integrate, expand, factor, latex\n",
    "\n",
    "model_name = \"llama-3.3-70b-versatile\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048943d",
   "metadata": {},
   "source": [
    "## What Are ‚ÄúTools‚Äù?\n",
    "\n",
    "**Tools** are capabilities you expose to the model. Each tool is defined using a standardized JSON structure. A tool can represent anything the model can call, such as:\n",
    "- A Python function  \n",
    "- A database query  \n",
    "- An external API call  \n",
    "- A local utility (file system, calculator, etc.)\n",
    "\n",
    "The model decides *when* to call a tool and provides structured arguments.\n",
    "\n",
    "\n",
    "### Tool Definition Format\n",
    "\n",
    "Tools are defined as a list of objects, each describing a function the model is allowed to call:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"function_name\",\n",
    "    \"description\": \"What this function does.\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"...\": { \"type\": \"...\" }\n",
    "      },\n",
    "      \"required\": [ ... ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Key Fields\n",
    "\n",
    "| Field        | Purpose                                                     |\n",
    "|--------------|-------------------------------------------------------------|\n",
    "| `type`       | Must be `\"function\"` for function-calling tools             |\n",
    "| `name`       | The name of your function or tool                           |\n",
    "| `description`| Helps the model decide when the function is appropriate     |\n",
    "| `parameters` | A JSON Schema describing valid arguments                    |\n",
    "| `required`   | Ensures the model provides the needed fields                |\n",
    "\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Retrieve the current weather for a given city.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\"},\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "This tells the model:\n",
    "- There is a function called **get_weather**\n",
    "- The function retrieves the current weather for a given city\n",
    "- It requires the city name as a string\n",
    "- It also accepts an optional unit (`\"celsius\"` or `\"fahrenheit\"`)\n",
    "- The model cannot call the function without providing a `city` argument\n",
    "\n",
    "You can find more information and a complete guide regarding function calling at the following guide: [link](https://platform.openai.com/docs/guides/function-calling#page-top)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef40a34",
   "metadata": {},
   "source": [
    "## üß™ Building Our Own Tools!\n",
    "\n",
    "In this section, we're going to create **several custom tools** but don‚Äôt worry, you won‚Äôt be writing the actual Python functions themselves. üéâ **All the underlying functions will be provided for you.**  \n",
    "\n",
    "Your job is to focus on the *AI side*: designing tool definitions, creating the schema, and teaching the model how to use what already exists.  \n",
    "\n",
    "\n",
    "### üî¢ Warm-Up: Creating a Simple Addition Tool\n",
    "\n",
    "Before we get into more complex examples, let's ease in with a warm-up exercise. We‚Äôll start by creating a tool that simply **adds two numbers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4b35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Adds two numbers and returns the result.\n",
    "    \"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379852bf",
   "metadata": {},
   "source": [
    "**`TODO:`** Define the `tools` object for the `add_numbers` function in the same fashion as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2142d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add_numbers\",\n",
    "            \"description\": \"Add two numbers.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"a\": {\"type\": \"number\"},\n",
    "                    \"b\": {\"type\": \"number\"}\n",
    "                },\n",
    "                \"required\": [\"a\", \"b\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc5771",
   "metadata": {},
   "source": [
    "## üß† Calling the Model With Our Tools\n",
    "\n",
    "Now that we‚Äôve defined our tools, it‚Äôs time to actually **use them**.  \n",
    "In this step, we‚Äôll send a request to the model *and* let it know which tools are available so it can decide whether one should be called.\n",
    "\n",
    "This is where everything comes together: You pass the model a user message and the set of tools you defined, and the model determines whether one of those tools is appropriate for the task. üöÄ\n",
    "\n",
    "When you run the provided code, it will:\n",
    "\n",
    "- Send a user request (for example, ‚ÄúAdd 12 and 30‚Äù)  \n",
    "- Tell the model about your available `tools`  \n",
    "- Allow the model to autonomously decide whether to call one of them  \n",
    "- Store the model‚Äôs response so you can inspect what it decided to do next\n",
    "\n",
    "In the next step, we‚Äôll take a look at the model‚Äôs response and see whether it chose to call your addition tool. üß©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e5c7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', annotations=None, executed_tools=None, function_call=None, reasoning=None, tool_calls=[ChatCompletionMessageToolCall(id='y55441ce4', function=Function(arguments='{\"a\":12,\"b\":30}', name='add_numbers'), type='function')])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = Groq()\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Add 12 and 30\"}],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "msg = resp.choices[0].message\n",
    "display(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a472c35",
   "metadata": {},
   "source": [
    "### üìù Understanding the Model‚Äôs Response\n",
    "\n",
    "When you inspect the model‚Äôs response, you‚Äôll see something that looks like this:\n",
    "\n",
    "```python\n",
    "ChatCompletionMessage(content=None, role='assistant', annotations=None, executed_tools=None, function_call=None, reasoning=None, tool_calls=[ChatCompletionMessageToolCall(id='5r87sgs67', function=Function(arguments='{\"a\":12,\"b\":30}', name='add_numbers'), type='function')])\n",
    "```\n",
    "\n",
    "\n",
    "Let‚Äôs break down what this means.\n",
    "\n",
    "\n",
    "Here‚Äôs what this means:\n",
    "\n",
    "- The model saw the user request **\"Add 12 and 30\"** and decided that the best way to answer is to call a tool rather than generate normal text.\n",
    "- `content=None` indicates there is **no natural-language response yet**, because the model is waiting for the tool to run.\n",
    "- `role='assistant'` simply shows the message is coming from the assistant.\n",
    "- The important part is the `tool_calls` list, which tells you that the model wants to execute a function-type tool.\n",
    "- Inside the tool call, you can see:\n",
    "  - the tool `type` is `\"function\"`\n",
    "  - the tool `name` is `\"add_numbers\"` ‚Äî the one you defined earlier\n",
    "  - the `arguments` field contains `{\"a\":12,\"b\":30}`, meaning the model correctly extracted the numbers from the user request\n",
    "\n",
    "Overall, this response shows that:\n",
    "\n",
    "- the tool was recognized  \n",
    "- the model chose it appropriately  \n",
    "- it generated valid arguments in the correct schema  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d43811",
   "metadata": {},
   "source": [
    "**`TODO:`** To verify that everything is going well, come up with a prompt that **should not** cause the model to call any tool. This helps confirm that the model only uses tools when appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e27dd706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The capital of France is Paris.', role='assistant', annotations=None, executed_tools=None, function_call=None, reasoning=None, tool_calls=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resp = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What's the capital of France?\"}],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "msg_ = resp.choices[0].message\n",
    "display(msg_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956a07b",
   "metadata": {},
   "source": [
    "### üß© Executing the Tool and Completing the Interaction\n",
    "\n",
    "After the model decides to call a tool, the general workflow is:\n",
    "\n",
    "1. **The model requests a tool call** with the arguments it wants to use.\n",
    "2. **You execute the tool yourself** (outside the model) using those arguments.\n",
    "3. **You send the tool‚Äôs result back to the model** in a special ‚Äútool‚Äù message.\n",
    "4. **The model uses that result** to generate its final, natural-language answer.\n",
    "\n",
    "This two-step loop is how tool-enabled models work:  \n",
    "the model identifies the tool it needs, you perform the action, and the model finishes the conversation using the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfab5dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer: The answer is 42.\n"
     ]
    }
   ],
   "source": [
    "# If the model decided to call a tool\n",
    "if msg.tool_calls:\n",
    "\n",
    "    # We'll execute the tool and get the result\n",
    "    tc = msg.tool_calls[0]\n",
    "    args = json.loads(tc.function.arguments)\n",
    "    result = add_numbers(**args)\n",
    "\n",
    "    # Now, we send the model the tool's result so it can finalize its answer\n",
    "    final = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Add 12 and 30\"},\n",
    "            msg,\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tc.id,\n",
    "                \"content\": str(result)\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"Final answer:\", final.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef0dc8",
   "metadata": {},
   "source": [
    "### üí∏ Currency Conversion Tool\n",
    "\n",
    "Now that you've successfully built and tested your first tool, it's time to move on to something a bit more practical. In this next section, we‚Äôll create a tool that **converts currency**, for example, from USD to EUR, or GBP to JPY.\n",
    "\n",
    "Just like before, the underlying conversion function `convert_currency` will be provided for you.  \n",
    "Your job is to define the tool schema, describe its inputs, and let the model know how to use it.\n",
    "\n",
    "To power this tool, we‚Äôll be using the following public API:\n",
    "\n",
    "**`https://api.frankfurter.app/latest?from=USD`**\n",
    "\n",
    "#### üßæ What is this API?\n",
    "\n",
    "The Frankfurter API is a free, open-source currency exchange API that provides **latest foreign exchange rates**.  It‚Äôs great to use because:\n",
    "- It **requires no API key**  \n",
    "- It returns simple, easy-to-parse JSON  \n",
    "- It supports many major currencies  \n",
    "\n",
    "#### ‚è≥ A small caveat\n",
    "\n",
    "The exchange rates are **updated relatively slowly** compared to financial-grade APIs. This is totally fine for learning purposes, but you should keep in mind that:\n",
    "- The request rate limit is very low\n",
    "- The rates may not reflect minute-by-minute market changes  \n",
    "- It‚Äôs meant for demos, testing, and education, not live trading  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e123a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rates():\n",
    "    # Frankfurter API, no key required\n",
    "    url = \"https://api.frankfurter.app/latest?from=USD\"\n",
    "    resp = requests.get(url)\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(\"Failed to fetch currency rates\")\n",
    "\n",
    "    data = resp.json()\n",
    "    return data[\"rates\"]\n",
    "\n",
    "\n",
    "def convert_currency(amount, from_currency, to_currency):\n",
    "    rates = get_rates()\n",
    "\n",
    "    from_currency = from_currency.upper()\n",
    "    to_currency = to_currency.upper()\n",
    "\n",
    "    if from_currency not in rates or to_currency not in rates:\n",
    "        raise ValueError(f\"Unsupported currency: {from_currency} or {to_currency}\")\n",
    "\n",
    "    # Convert to USD ‚Üí then to target\n",
    "    usd_value = amount / rates[from_currency]\n",
    "    converted = usd_value * rates[to_currency]\n",
    "\n",
    "    return round(converted, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028adf9",
   "metadata": {},
   "source": [
    "**`TODO:`** Using the function provided to you, define a proper **tool schema** for the currency converter.  \n",
    "Your tool should clearly specify:\n",
    "\n",
    "- the name of the tool  \n",
    "- a short description of what it does  \n",
    "- all required inputs (e.g., `from_currency`, `to_currency`, `amount`)  \n",
    "- the correct JSON Schema types for each input  \n",
    "\n",
    "After defining the tool, test it by sending the model a prompt that *should* trigger a currency conversion (for example: ‚ÄúConvert 50 USD to EUR‚Äù). Make sure the model selects your tool and generates valid arguments.\n",
    "\n",
    "Once that happens, **execute the tool call yourself** using the provided function, and then **return its result back to the model** so it can produce the final natural-language answer.\n",
    "\n",
    "*Hint:* The overall procedure is exactly the same as in the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e7b65cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer: The current exchange rate is 1 EUR = 180.898 JPY. \n",
      "\n",
      "150 EUR is approximately 27127 JPY.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Convert 150 EUR to JPY.\"\n",
    "\n",
    "# Defining the tool schema for currency conversion\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"convert_currency\",\n",
    "            \"description\": \"Convert an amount of money from one currency to another using live exchange rates.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"amount\": {\"type\": \"number\"},\n",
    "                    \"from_currency\": {\"type\": \"string\"},\n",
    "                    \"to_currency\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"amount\", \"from_currency\", \"to_currency\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Sending a request to the model to convert currency\n",
    "response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "# If the model decided to call the currency conversion tool\n",
    "if message.tool_calls:\n",
    "    # We'll execute the tool and get the result\n",
    "    t = message.tool_calls[0]\n",
    "    args = json.loads(t.function.arguments)\n",
    "    result = convert_currency(**args)\n",
    "\n",
    "# Now, we send the model the tool's result so it can finalize its answer\n",
    "followup = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        message,\n",
    "        {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": t.id,\n",
    "            \"content\": str(result)\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Final answer:\", followup.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd672e82",
   "metadata": {},
   "source": [
    "### üßÆ A Symbolic Math Helper (SymPy)\n",
    "\n",
    "Now we‚Äôre moving on to a more advanced and very powerful tool: a **general-purpose symbolic math assistant** built using **SymPy**.\n",
    "\n",
    "This tool can:\n",
    "- interpret a math expression written as a string  \n",
    "- perform algebraic operations (simplification, factoring, expanding, solving, etc.)  \n",
    "- perform calculus operations (derivatives, integrals, limits)  \n",
    "- return the result in both **plain text** and **LaTeX**, so it‚Äôs suitable for readable output or rendering in notebooks\n",
    "\n",
    "This tool is especially useful when you want the model to offload symbolic computation to a reliable math engine rather than attempt it purely through text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bba579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_math(task: str, expression: str, variable: str=None) -> dict:\n",
    "    \"\"\"\n",
    "    Performs symbolic math operations using SymPy.\n",
    "    Parameters:\n",
    "    - task: The type of operation to perform (e.g., \"simplify\", \"solve\", \"derivative\", \"integral\", \"expand\", \"factor\").\n",
    "    - expression: The mathematical expression as a string.\n",
    "    - variable: The variable with respect to which to perform operations like derivative or integral (optional).\n",
    "    Returns:\n",
    "    - A dictionary with the result in string and LaTeX format, or an error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse expression safely\n",
    "        expr = sympify(expression)\n",
    "\n",
    "        # Optional variable parsing\n",
    "        var = symbols(variable) if variable else None\n",
    "\n",
    "        if task == \"simplify\":\n",
    "            result = simplify(expr)\n",
    "\n",
    "        elif task == \"solve\":\n",
    "            result = solve(expr)\n",
    "\n",
    "        elif task == \"derivative\":\n",
    "            if var is None:\n",
    "                raise ValueError(\"Derivative requires 'variable'\")\n",
    "            result = diff(expr, var)\n",
    "\n",
    "        elif task == \"integral\":\n",
    "            if var is None:\n",
    "                raise ValueError(\"Integral requires 'variable'\")\n",
    "            result = integrate(expr, var)\n",
    "\n",
    "        elif task == \"expand\":\n",
    "            result = expand(expr)\n",
    "\n",
    "        elif task == \"factor\":\n",
    "            result = factor(expr)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task: {task}\")\n",
    "\n",
    "        # Return both raw string and LaTeX for LLM formatting\n",
    "        return {\n",
    "            \"result_str\": str(result),\n",
    "            \"result_latex\": latex(result)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed3277",
   "metadata": {},
   "source": [
    "**`TODO:`** Using the SymPy-based function provided to you, define a **tool schema** for the symbolic math helper. Your schema should include:\n",
    "\n",
    "- the tool‚Äôs name  \n",
    "- a clear description of what the tool can do  \n",
    "- all required inputs (e.g., `expression`, `task`)  \n",
    "- appropriate JSON Schema types, such as strings or enums for the operation type  \n",
    "\n",
    "After defining the tool, test it by sending the model prompts that *should* trigger symbolic math actions (for example: \"Differentiate x^3 * sin(x) with respect to x.\"). Verify that the model selects your math tool and produces valid arguments.\n",
    "\n",
    "Once the model requests the tool, **execute the SymPy function yourself**, then **return the result back to the model** so it can generate the final explanation or formatted answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcef1192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The derivative of x^3 * sin(x) with respect to x is x^3 * cos(x) + 3x^2 * sin(x).\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Differentiate x^3 * sin(x) with respect to x.\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"symbolic_math\",\n",
    "            \"description\": \"Perform symbolic math operations using SymPy: simplify, solve, derivative, integral, expand, or factor an expression.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"task\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"simplify\", \"solve\", \"derivative\", \"integral\", \"expand\", \"factor\"]\n",
    "                    },\n",
    "                    \"expression\": {\"type\": \"string\"},\n",
    "                    \"variable\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Variable with respect to which to differentiate or integrate\",\n",
    "                        \"nullable\": True\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"task\", \"expression\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Differentiate x^3 * sin(x) with respect to x.\"}\n",
    "    ],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "if message.tool_calls:\n",
    "    call = message.tool_calls[0]\n",
    "    args = json.loads(call.function.arguments)\n",
    "    result = symbolic_math(**args)\n",
    "\n",
    "followup = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        message,\n",
    "        {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": call.id,\n",
    "            \"content\": json.dumps(result)\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(followup.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f1277",
   "metadata": {},
   "source": [
    "## üå¶Ô∏è A Weather Retrieval System (Open-Meteo)\n",
    "\n",
    "Our next tool is a more realistic, multi-step system that retrieves live weather information for a given city. This tool demonstrates how an agent can coordinate several external API calls to produce a polished result.\n",
    "\n",
    "Here‚Äôs what the tool does:\n",
    "\n",
    "- It takes a **city name** as input.\n",
    "- It uses the **Open-Meteo Geocoding API** to convert that city into geographic coordinates (latitude and longitude).\n",
    "- It then sends those coordinates to the **Open-Meteo Forecast API** to retrieve current weather details.\n",
    "- Both API calls are **cached**, so repeated queries are faster and avoid redundant network usage.\n",
    "- After getting the weather data, the tool:\n",
    "  - converts the temperature into the user‚Äôs preferred unit (Celsius, Fahrenheit, or Kelvin),\n",
    "  - collects wind speed, wind direction, and timestamp,\n",
    "  - and returns a clean, structured summary containing the city, country, temperature, wind info, and time.\n",
    "- If anything goes wrong (e.g., API failure, city not found), the tool returns a **helpful error message** instead.\n",
    "\n",
    "In the end, the actual function you'll call for this tool is simply **`get_weather`**, which wraps all the steps above into one convenient interface.\n",
    "\n",
    "This tool is a great example of how an LLM can collaborate with external systems to provide accurate, real-time information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "616211cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small cache to avoid repeated API calls\n",
    "@lru_cache(maxsize=128)\n",
    "def geocode(location: str):\n",
    "    url = \"https://geocoding-api.open-meteo.com/v1/search\"\n",
    "    resp = requests.get(url, params={\"name\": location, \"count\": 5, \"language\": \"en\"})\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(\"Geocoding service unavailable\")\n",
    "\n",
    "    data = resp.json()\n",
    "\n",
    "    if \"results\" not in data or not data[\"results\"]:\n",
    "        raise ValueError(f\"No matching city found for '{location}'\")\n",
    "\n",
    "    # Pick the first (best) result\n",
    "    best = data[\"results\"][0]\n",
    "\n",
    "    return {\n",
    "        \"name\": best[\"name\"],\n",
    "        \"lat\": best[\"latitude\"],\n",
    "        \"lon\": best[\"longitude\"],\n",
    "        \"country\": best.get(\"country\", \"\"),\n",
    "    }\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def fetch_weather(lat, lon):\n",
    "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    resp = requests.get(url, params={\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"current_weather\": True\n",
    "    })\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(\"Weather service unavailable\")\n",
    "\n",
    "    data = resp.json()\n",
    "\n",
    "    if \"current_weather\" not in data:\n",
    "        raise Exception(\"Weather data missing\")\n",
    "\n",
    "    return data[\"current_weather\"]\n",
    "\n",
    "\n",
    "def convert_temp(celsius, units):\n",
    "    if units == \"celsius\":\n",
    "        return celsius\n",
    "    elif units == \"fahrenheit\":\n",
    "        return celsius * 9/5 + 32\n",
    "    elif units == \"kelvin\":\n",
    "        return celsius + 273.15\n",
    "    else:\n",
    "        raise ValueError(\"Invalid units\")\n",
    "\n",
    "\n",
    "def get_weather(location: str, units: str = \"celsius\"):\n",
    "    try:\n",
    "        geo = geocode(location)\n",
    "        weather = fetch_weather(geo[\"lat\"], geo[\"lon\"])\n",
    "\n",
    "        temp_c = weather[\"temperature\"]\n",
    "        temp_u = convert_temp(temp_c, units)\n",
    "\n",
    "        return {\n",
    "            \"location\": geo[\"name\"],\n",
    "            \"country\": geo[\"country\"],\n",
    "            \"temperature\": round(temp_u, 2),\n",
    "            \"units\": units,\n",
    "            \"wind_speed\": weather[\"windspeed\"],\n",
    "            \"wind_direction\": weather[\"winddirection\"],\n",
    "            \"time\": weather[\"time\"]\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ce10b",
   "metadata": {},
   "source": [
    "**`TODO:`** Using the provided `get_weather` function, create a **tool schema** that allows the model to request weather information. Your schema should include:\n",
    "- the tool‚Äôs name (`get_weather`)  \n",
    "- a clear description of what the tool does  \n",
    "- the required inputs (e.g., `city`, `unit`)  \n",
    "- correct JSON Schema types, and enums where appropriate (such as allowed temperature units)\n",
    "\n",
    "After defining the tool, test it by prompting the model with a query that *should* trigger weather retrieval (e.g., \"What is the weather in Tokyo right now in Fahrenheit?\"). Check that the model selects your weather tool and produces valid arguments.\n",
    "\n",
    "Finally, **execute the tool call using `get_weather`**, then **send its result back to the model** so it can generate the final, user-friendly weather report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "853095f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Tokyo is 44.42 degrees Fahrenheit.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the weather in Tokyo right now in Fahrenheit?\"\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Retrieve current weather for a given city name\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"City or place name to get weather for\"\n",
    "                    },\n",
    "                    \"units\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\", \"kelvin\"],\n",
    "                        \"default\": \"celsius\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "if message.tool_calls:\n",
    "    call = message.tool_calls[0]\n",
    "    args = json.loads(call.function.arguments)\n",
    "    result = get_weather(**args)\n",
    "\n",
    "followup = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        message,\n",
    "        {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": call.id,\n",
    "            \"content\": json.dumps(result)\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(followup.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf2573f",
   "metadata": {},
   "source": [
    "### üì∞ A News Retrieval and Article Extraction System\n",
    "\n",
    "Our final tool in this sequence is a small but powerful news-fetching system. It demonstrates how an agent can interact with third-party APIs, process multiple results, and gather detailed information from the web.\n",
    "\n",
    "Here‚Äôs what the tool does:\n",
    "\n",
    "- It uses the **NewsAPI** service to search for recent articles based on a user-provided query.\n",
    "- For each returned article, it attempts to download and extract the **full text** using the **Newspaper4k** library.\n",
    "- The `extract_text` function handles downloading and parsing article content from a URL, and it is **cached** so that repeated requests for the same article do not trigger additional network calls.\n",
    "- The `fetch_news` function:\n",
    "  - performs the news search,\n",
    "  - checks for errors (e.g., missing API key, invalid query),\n",
    "  - processes each article by collecting its title, source, publication time, URL,\n",
    "  - and includes either the extracted full text or, if extraction fails, the article‚Äôs description instead.\n",
    "\n",
    "The final output is a clean, structured list of article details, or an informative error message if something goes wrong.\n",
    "\n",
    "#### üß© Extra Exercise (Optional)\n",
    "\n",
    "If you want to actually run this tool end-to-end, you‚Äôll need to install the necessary libraries and register for an API key:\n",
    "\n",
    "- Install the text extraction library (a modern fork of Newspaper3k):  \n",
    "  **`pip install newspaper4k`**\n",
    "\n",
    "- Register for a free NewsAPI key:  \n",
    "  **https://newsapi.org/register**\n",
    "\n",
    "This exercise is optional, but it‚Äôs a great way to experiment with live article retrieval and full-text extraction in a real agent pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to True if you want to install newspaper4k\n",
    "if False:\n",
    "    !pip install newspaper4k\n",
    "    from newspaper import Article\n",
    "    NEWS_API_KEY = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed95f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching to avoid excessive API calls\n",
    "@lru_cache(maxsize=256)\n",
    "def extract_text(url: str):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def fetch_news(query, max_articles=5, language=\"en\"):\n",
    "    try:\n",
    "        # 1. Search for news articles\n",
    "        url = \"https://newsapi.org/v2/everything\"\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"apiKey\": NEWS_API_KEY,\n",
    "            \"sortBy\": \"publishedAt\",\n",
    "            \"pageSize\": max_articles,\n",
    "            \"language\": language\n",
    "        }\n",
    "\n",
    "        resp = requests.get(url, params=params)\n",
    "        data = resp.json()\n",
    "\n",
    "        if resp.status_code != 200 or data.get(\"status\") != \"ok\":\n",
    "            return {\"error\": f\"News API error: {data.get('message')}\"}\n",
    "\n",
    "        articles = data[\"articles\"]\n",
    "\n",
    "        cleaned = []\n",
    "\n",
    "        # 2. Extract full text for each article\n",
    "        for art in articles:\n",
    "            url = art[\"url\"]\n",
    "            text = extract_text(url)\n",
    "\n",
    "            cleaned.append({\n",
    "                \"title\": art[\"title\"],\n",
    "                \"source\": art[\"source\"][\"name\"],\n",
    "                \"url\": url,\n",
    "                \"published_at\": art[\"publishedAt\"],\n",
    "                \"text\": text if text else art.get(\"description\", \"\")\n",
    "            })\n",
    "\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"results\": cleaned\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc4c23",
   "metadata": {},
   "source": [
    "**`TODO:`** Using the provided `fetch_news` function, define a **tool schema** that allows the model to request news searches. Your schema should include:\n",
    "\n",
    "- the tool‚Äôs name (`fetch_news`)  \n",
    "- a clear description of what the tool does  \n",
    "- the required inputs (e.g., `query`)  \n",
    "- correct JSON Schema types \n",
    "\n",
    "After defining the tool, test it by prompting the model with a query that *should* trigger a news search (for example: \"Give me a brief summary of the latest news about Ethereum.\"). Check that the model selects your news tool and produces valid arguments.\n",
    "\n",
    "Once the model requests the tool, **execute the tool call using `fetch_news`**, then **return the result back to the model** so it can generate the final summary or explanation for the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "279c098f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest news about Ethereum includes:\n",
      "\n",
      "* Ethereum (ETH) is a cheaper per coin than Bitcoin (BTC), yet it keeps trailing in performance. Institutions favor Bitcoin's simple \"digital gold\" pitch and tight supply, while Ethereum's case is more complex.\n",
      "* Bitcoin climbed back to $93,000 on Tuesday as El Salvador announced its largest single-day BTC purchase. Ethereum, XRP, and Dogecoin also rose 3%.\n",
      "* Paxos Labs has launched USDG0, an omnichain extension of its regulated USDG stablecoin, bringing fully backed dollar liquidity to Hyperliquid, Plume, and Aptos through LayerZero's OFT standard.\n",
      "* 0xbow, a Vitalik Buterin-backed privacy protocol, has closed a $3.5M round for compliant crypto privacy technology following Ethereum Foundation integration. The protocol has processed more than $6M in transaction volume.\n",
      "\n",
      "These are just a few examples of the latest news about Ethereum. For more information, please visit the provided links to read the full articles.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me a brief summary of the latest news about Ethereum.\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"fetch_news\",\n",
    "            \"description\": \"Fetch recent news articles about a topic and extract readable text.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Search terms for the news topic\"\n",
    "                    },\n",
    "                    \"max_articles\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"default\": 5\n",
    "                    },\n",
    "                    \"language\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"default\": \"en\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "if message.tool_calls:\n",
    "    call = message.tool_calls[0]\n",
    "    args = json.loads(call.function.arguments)\n",
    "    result = fetch_news(**args)\n",
    "\n",
    "followup = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        message,\n",
    "        {\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": call.id,\n",
    "            \"content\": json.dumps(result)\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(followup.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87acb6",
   "metadata": {},
   "source": [
    "## üéØ Conclusion\n",
    "\n",
    "You‚Äôve now built several tools, connected them to a model, and experienced how function calling turns an LLM into an **agent** that can take actions instead of just generating text.  \n",
    "This process ‚Äî defining tools ‚Üí letting the model choose ‚Üí executing ‚Üí returning results, is the fundamental loop behind modern AI agent systems.\n",
    "\n",
    "Of course, this notebook is only an introduction. Agents can become far more capable when you add elements like planning, memory, multi-step reasoning, safety constraints, and orchestration frameworks. If you want to dive deeper, here are some recommended resources:\n",
    "\n",
    "### üìö Further Resources\n",
    "\n",
    "**Building Effective Agents** ‚Äî [link](https://www.anthropic.com/engineering/building-effective-agents)\n",
    "\n",
    "A step-by-step guide that starts from ‚ÄúWhat is an agent?‚Äù and walks through how to design and use them effectively.\n",
    "\n",
    "**Visual Guide to Agents & Tools** ‚Äî [link](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-llm-agents)\n",
    "\n",
    "A resource filled with helpful diagrams explaining how agents work, how they plan, and how tool calling fits into the overall loop.\n",
    "\n",
    "**Hugging Face AI Agents Course** ‚Äî [link](https://huggingface.co/learn/agents-course/en/unit0/introduction)\n",
    "\n",
    "A more in-depth course. Useful as a general learning resource, specialized to the Hugging Face library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
